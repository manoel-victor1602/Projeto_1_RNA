{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from math import ceil, sqrt\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piramid(alpha=2, n_in=7, n_out=1):\n",
    "    neurons = ceil(alpha * sqrt(n_in * n_out))\n",
    "    ret = [(neurons,)]\n",
    "    ret += [(neurons-n, n) for n in range(1, neurons)]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'activation': ['logistic', 'relu', 'tanh'], \n",
    "    'max_iter': [800, 900, 1000],\n",
    "    'learning_rate_init': [0.001, 0.003, 0.0005],\n",
    "    'hidden_layer_sizes': list(piramid(alpha=0.5, n_in=9) + piramid(alpha=2, n_in=9) + piramid(alpha=3, n_in=9))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataR2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  Classification  \n",
       "0  417.114               1  \n",
       "1  468.786               1  \n",
       "2  554.697               1  \n",
       "3  928.220               1  \n",
       "4  773.920               1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(2,), learning_rate_init=0.0005, max_iter=1000)\n",
    "model_2 = MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(2,), learning_rate_init=0.00008, max_iter=1100)\n",
    "model_3 = MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(3,3), learning_rate_init=0.0005, max_iter=1000)\n",
    "model_4 = MLPClassifier(solver='lbfgs', activation='relu', hidden_layer_sizes=(1,8), learning_rate_init=0.001, max_iter=1000)\n",
    "model_5 = MLPClassifier(solver='lbfgs', activation='relu', hidden_layer_sizes=(2,), learning_rate_init=0.0005, max_iter=1000)\n",
    "model_6 = MLPClassifier(solver='lbfgs', activation='tanh', hidden_layer_sizes=(5,1), learning_rate_init=0.001, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train)\n",
    "y_pred = model_1.predict(X_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741935483870968\n",
      "0.7407407407407408\n",
      "0.8\n",
      "0.7857142857142857\n",
      "0.5454545454545454\n",
      "0.6666666666666666\n",
      "0.4761904761904762\n",
      "0.7407407407407408\n",
      "0.8275862068965517\n",
      "0.8148148148148148\n",
      "0.4761904761904762\n",
      "0.5454545454545454\n",
      "0.8181818181818182\n",
      "0.5217391304347826\n",
      "0.6666666666666666\n",
      "0.4444444444444444\n",
      "0.7826086956521738\n",
      "0.7333333333333334\n",
      "0.7857142857142857\n",
      "0.8148148148148148\n",
      "0.6923076923076924\n",
      "0.8275862068965517\n",
      "0.4210526315789474\n",
      "0.5454545454545454\n",
      "0.6086956521739131\n",
      "0.7857142857142857\n",
      "0.5833333333333334\n",
      "0.4761904761904762\n",
      "0.7826086956521738\n",
      "0.7272727272727272\n",
      "0.5454545454545454\n",
      "0.64\n",
      "0.8275862068965517\n",
      "0.6923076923076924\n",
      "0.8\n",
      "0.6666666666666666\n",
      "0.7826086956521738\n",
      "0.7407407407407408\n",
      "0.5217391304347826\n",
      "0.4\n",
      "0.75\n",
      "0.7826086956521738\n",
      "0.888888888888889\n",
      "0.7272727272727272\n",
      "0.5599999999999999\n",
      "0.7407407407407408\n",
      "0.8799999999999999\n",
      "0.8275862068965517\n",
      "0.45454545454545453\n",
      "0.7857142857142857\n",
      "0.5833333333333334\n",
      "0.7272727272727272\n",
      "0.6\n",
      "0.4761904761904762\n",
      "0.7692307692307692\n",
      "0.7741935483870968\n",
      "0.7272727272727272\n",
      "0.5454545454545454\n",
      "0.6666666666666666\n",
      "0.8148148148148148\n",
      "0.4761904761904762\n",
      "0.7857142857142857\n",
      "0.5217391304347826\n",
      "0.5217391304347826\n",
      "0.4761904761904762\n",
      "0.4\n",
      "0.7826086956521738\n",
      "0.5454545454545454\n",
      "0.6\n",
      "0.5217391304347826\n",
      "0.7857142857142857\n",
      "0.6666666666666665\n",
      "0.8799999999999999\n",
      "0.8275862068965517\n",
      "0.4\n",
      "0.6363636363636365\n",
      "0.7857142857142857\n",
      "0.4210526315789474\n",
      "0.7272727272727272\n",
      "0.5714285714285715\n",
      "0.6923076923076924\n",
      "0.8148148148148148\n",
      "0.8571428571428571\n",
      "0.8571428571428571\n",
      "0.4444444444444444\n",
      "0.5454545454545454\n",
      "0.7199999999999999\n",
      "0.5217391304347826\n",
      "0.7857142857142857\n",
      "0.7692307692307692\n",
      "0.8799999999999999\n",
      "0.45454545454545453\n",
      "0.4761904761904762\n",
      "0.7407407407407408\n",
      "0.6666666666666666\n",
      "0.8275862068965517\n",
      "0.6666666666666666\n",
      "0.5714285714285715\n",
      "0.64\n",
      "0.5217391304347826\n",
      "0.7199999999999999\n",
      "0.761904761904762\n",
      "0.6923076923076924\n",
      "0.7272727272727272\n",
      "0.7692307692307692\n",
      "0.5454545454545454\n",
      "0.8148148148148148\n",
      "0.7407407407407408\n",
      "0.7826086956521738\n",
      "0.6666666666666666\n",
      "0.6428571428571429\n",
      "0.6666666666666666\n",
      "0.5454545454545454\n",
      "0.64\n",
      "0.5217391304347826\n",
      "0.7826086956521738\n",
      "0.7857142857142857\n",
      "0.4444444444444444\n",
      "0.45454545454545453\n",
      "0.4210526315789474\n",
      "0.5714285714285715\n",
      "0.45454545454545453\n",
      "0.6153846153846153\n",
      "0.7142857142857143\n",
      "0.7857142857142857\n",
      "0.5\n",
      "0.5\n",
      "0.5454545454545454\n",
      "0.6086956521739131\n",
      "0.5217391304347826\n",
      "0.8181818181818182\n",
      "0.8571428571428571\n",
      "0.7272727272727272\n",
      "0.8\n",
      "0.7857142857142857\n",
      "0.8\n",
      "0.45454545454545453\n",
      "0.7272727272727272\n",
      "0.8799999999999999\n",
      "0.5599999999999999\n",
      "0.5217391304347826\n",
      "0.7407407407407408\n",
      "0.6956521739130435\n",
      "0.5599999999999999\n",
      "0.7826086956521738\n",
      "0.7407407407407408\n",
      "0.5454545454545454\n",
      "0.8\n",
      "0.7407407407407408\n",
      "0.6666666666666666\n",
      "0.4444444444444444\n",
      "0.6666666666666666\n",
      "0.6923076923076924\n",
      "0.6153846153846153\n",
      "0.8\n",
      "0.4\n",
      "0.7692307692307692\n",
      "0.5217391304347826\n",
      "0.6\n",
      "0.75\n",
      "0.6956521739130435\n",
      "0.8695652173913043\n",
      "0.6923076923076924\n",
      "0.7407407407407408\n",
      "0.6\n",
      "0.7407407407407408\n",
      "0.6923076923076924\n",
      "0.7826086956521738\n",
      "0.4210526315789474\n",
      "0.7692307692307692\n",
      "0.5217391304347826\n",
      "0.5833333333333334\n",
      "0.75\n",
      "0.64\n",
      "0.8\n",
      "0.6363636363636365\n",
      "0.8275862068965517\n",
      "0.75\n",
      "0.7272727272727272\n",
      "0.5\n",
      "0.6666666666666666\n",
      "0.6896551724137931\n",
      "0.8275862068965517\n",
      "0.5217391304347826\n",
      "0.7857142857142857\n",
      "0.5454545454545454\n",
      "0.6666666666666666\n",
      "0.4444444444444444\n",
      "0.8333333333333334\n",
      "0.8571428571428571\n",
      "0.8275862068965517\n",
      "0.6666666666666665\n",
      "0.6666666666666666\n",
      "0.7407407407407408\n",
      "0.8275862068965517\n",
      "0.45454545454545453\n",
      "0.6923076923076924\n",
      "0.7199999999999999\n",
      "0.7142857142857143\n",
      "0.5217391304347826\n",
      "0.7272727272727272\n",
      "0.8\n",
      "0.5217391304347826\n",
      "0.7199999999999999\n",
      "0.7857142857142857\n",
      "0.7272727272727272\n",
      "0.8148148148148148\n",
      "0.7826086956521738\n",
      "0.5217391304347826\n",
      "0.380952380952381\n",
      "0.7272727272727272\n",
      "0.7272727272727272\n",
      "0.7857142857142857\n",
      "0.8\n",
      "0.7272727272727272\n",
      "0.5454545454545454\n",
      "0.8148148148148148\n",
      "0.5217391304347826\n",
      "0.5217391304347826\n",
      "0.8\n",
      "0.7741935483870968\n",
      "0.7857142857142857\n",
      "0.8275862068965517\n",
      "0.6956521739130435\n",
      "0.7857142857142857\n",
      "0.5454545454545454\n",
      "0.6153846153846153\n",
      "0.8\n",
      "0.5\n",
      "0.4210526315789474\n",
      "0.7826086956521738\n",
      "0.7857142857142857\n",
      "0.6923076923076924\n",
      "0.8\n",
      "0.7857142857142857\n",
      "0.7407407407407408\n",
      "0.7857142857142857\n",
      "0.7857142857142857\n",
      "0.5714285714285715\n",
      "0.7857142857142857\n",
      "0.6923076923076924\n",
      "0.45454545454545453\n",
      "0.6086956521739131\n",
      "0.7692307692307692\n",
      "0.5714285714285715\n",
      "0.8275862068965517\n",
      "0.7272727272727272\n",
      "0.45454545454545453\n",
      "0.5217391304347826\n",
      "0.7857142857142857\n",
      "0.7407407407407408\n",
      "0.7407407407407408\n",
      "0.5454545454545454\n",
      "0.7741935483870968\n",
      "0.7692307692307692\n",
      "0.6666666666666666\n",
      "0.7857142857142857\n",
      "0.7857142857142857\n",
      "0.8799999999999999\n",
      "0.7857142857142857\n",
      "0.5217391304347826\n",
      "0.45454545454545453\n",
      "0.6\n",
      "0.7692307692307692\n",
      "0.5\n",
      "0.7142857142857143\n",
      "0.6666666666666666\n",
      "0.5217391304347826\n",
      "0.7407407407407408\n",
      "0.75\n",
      "0.7857142857142857\n",
      "0.5217391304347826\n",
      "0.8148148148148148\n",
      "0.7692307692307692\n",
      "0.6923076923076924\n",
      "0.5217391304347826\n",
      "0.4210526315789474\n",
      "0.7272727272727272\n",
      "0.4\n",
      "0.8148148148148148\n",
      "0.7857142857142857\n",
      "0.4444444444444444\n",
      "0.8181818181818182\n",
      "0.8148148148148148\n",
      "0.8571428571428571\n",
      "0.6666666666666666\n",
      "0.7857142857142857\n",
      "0.8148148148148148\n",
      "0.4210526315789474\n",
      "0.8\n",
      "0.64\n",
      "0.8148148148148148\n",
      "0.8275862068965517\n",
      "0.7857142857142857\n",
      "0.7826086956521738\n",
      "0.8799999999999999\n",
      "0.7692307692307692\n",
      "0.4761904761904762\n",
      "0.7826086956521738\n",
      "0.7826086956521738\n",
      "0.8\n",
      "0.64\n",
      "0.7741935483870968\n",
      "0.5454545454545454\n",
      "0.8799999999999999\n",
      "0.7407407407407408\n",
      "0.6363636363636365\n",
      "0.5217391304347826\n",
      "0.6923076923076924\n",
      "0.5217391304347826\n",
      "0.45454545454545453\n",
      "0.5\n",
      "0.5454545454545454\n",
      "0.6923076923076924\n",
      "0.7741935483870968\n",
      "0.4210526315789474\n",
      "0.7407407407407408\n",
      "0.45454545454545453\n",
      "0.7857142857142857\n",
      "0.8148148148148148\n",
      "0.4761904761904762\n",
      "0.64\n",
      "0.6956521739130435\n",
      "0.7857142857142857\n",
      "0.5454545454545454\n",
      "0.8275862068965517\n",
      "0.5\n",
      "0.7199999999999999\n",
      "0.5714285714285715\n",
      "0.6086956521739131\n",
      "0.5454545454545454\n",
      "0.7407407407407408\n",
      "0.5217391304347826\n",
      "0.4\n",
      "0.8\n",
      "0.7272727272727272\n",
      "0.8461538461538461\n",
      "0.7741935483870968\n",
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.7741935483870968\n",
      "0.7407407407407408\n",
      "0.6956521739130435\n",
      "0.6666666666666666\n",
      "0.7857142857142857\n",
      "0.8571428571428571\n",
      "0.64\n",
      "0.7407407407407408\n",
      "0.5217391304347826\n",
      "0.5217391304347826\n",
      "0.8148148148148148\n",
      "0.7826086956521738\n",
      "0.7857142857142857\n",
      "0.8\n",
      "0.6363636363636365\n",
      "0.45454545454545453\n",
      "0.6\n",
      "0.6666666666666666\n",
      "0.8\n",
      "0.8\n",
      "0.4761904761904762\n",
      "0.7826086956521738\n",
      "0.7407407407407408\n",
      "0.7407407407407408\n",
      "0.64\n",
      "0.7407407407407408\n",
      "0.7692307692307692\n",
      "0.5217391304347826\n",
      "0.7272727272727272\n",
      "0.6\n",
      "0.6923076923076924\n",
      "0.5217391304347826\n",
      "0.7857142857142857\n",
      "0.7741935483870968\n",
      "0.64\n",
      "0.5454545454545454\n",
      "0.4761904761904762\n",
      "0.5217391304347826\n",
      "0.8275862068965517\n",
      "0.7857142857142857\n",
      "0.8148148148148148\n",
      "0.5217391304347826\n",
      "0.45454545454545453\n",
      "0.6666666666666666\n",
      "0.5599999999999999\n",
      "0.6666666666666666\n",
      "0.7826086956521738\n",
      "0.4444444444444444\n",
      "0.7407407407407408\n",
      "0.7199999999999999\n",
      "0.5217391304347826\n",
      "0.64\n",
      "0.7407407407407408\n",
      "0.7741935483870968\n",
      "0.8\n",
      "0.4\n",
      "0.75\n",
      "0.6923076923076924\n",
      "0.64\n",
      "0.4210526315789474\n",
      "0.5217391304347826\n",
      "0.7857142857142857\n",
      "0.8\n",
      "0.7857142857142857\n",
      "0.43478260869565216\n",
      "0.7407407407407408\n",
      "0.64\n",
      "0.7142857142857143\n",
      "0.5217391304347826\n",
      "0.6923076923076924\n",
      "0.8\n",
      "0.7741935483870968\n",
      "0.7407407407407408\n",
      "0.6666666666666666\n",
      "0.6153846153846153\n",
      "0.8275862068965517\n",
      "0.4444444444444444\n",
      "0.8275862068965517\n",
      "0.6923076923076924\n",
      "0.4210526315789474\n",
      "0.8275862068965517\n",
      "0.5\n",
      "0.4761904761904762\n",
      "0.5217391304347826\n",
      "0.7407407407407408\n",
      "0.7272727272727272\n",
      "0.7857142857142857\n",
      "0.7741935483870968\n",
      "0.64\n",
      "0.6923076923076924\n",
      "0.5454545454545454\n",
      "0.5217391304347826\n",
      "0.6086956521739131\n",
      "0.7199999999999999\n",
      "0.5217391304347826\n",
      "0.8275862068965517\n",
      "0.6\n",
      "0.8571428571428571\n",
      "0.8275862068965517\n",
      "0.5217391304347826\n",
      "0.8\n",
      "0.6666666666666666\n",
      "0.7826086956521738\n",
      "0.8148148148148148\n",
      "0.7692307692307692\n",
      "0.6666666666666666\n",
      "0.8\n",
      "0.5714285714285715\n",
      "0.7857142857142857\n",
      "0.7857142857142857\n",
      "0.8\n",
      "0.5217391304347826\n",
      "0.6923076923076924\n",
      "0.5454545454545454\n",
      "0.7692307692307692\n",
      "0.6923076923076924\n",
      "0.5217391304347826\n",
      "0.5217391304347826\n",
      "0.5454545454545454\n",
      "0.7857142857142857\n",
      "0.7857142857142857\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "f_score = 0\n",
    "while(f_score < 0.9):\n",
    "    model_2.fit(X_train, y_train)\n",
    "    y_pred = model_2.predict(X_test)\n",
    "    f_score = f1_score(y_pred=y_pred, y_true=y_test)\n",
    "    print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'model': model,\n",
    "     'y_pred': y_pred,\n",
    "     'f1_score': f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  1],\n",
       "       [ 1, 11]])"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(d, open('good_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train, y_train)\n",
    "y_pred = model_3.predict(X_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(X_train, y_train)\n",
    "y_pred = model_4.predict(X_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(X_train, y_train)\n",
    "y_pred = model_5.predict(X_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.761904761904762"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.fit(X_train, y_train)\n",
    "y_pred = model_6.predict(X_test)\n",
    "f1_score(y_pred=y_pred, y_true=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
