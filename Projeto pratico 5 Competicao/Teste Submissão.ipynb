{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open('good_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "        beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "        hidden_layer_sizes=(9,), learning_rate='constant',\n",
       "        learning_rate_init=0.0005, max_iter=800, momentum=0.9,\n",
       "        nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "        shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "        verbose=False, warm_start=False),\n",
       " 'y_pred': array([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1,\n",
       "        2, 1], dtype=int64),\n",
       " 'f1_score': 0.9166666666666666}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = results['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.BMI = df_data.BMI.apply(round, args=[4])\n",
    "df_data.HOMA = df_data.HOMA.apply(round, args=[4])\n",
    "df_data.Adiponectin = df_data.Adiponectin.apply(round, args=[4])\n",
    "df_data.Resistin = df_data.Resistin.apply(round, args=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.iloc[:, :-1].drop('id', axis=1)\n",
    "y = df_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.8333333333333333\n",
      "0.4444444444444445\n",
      "0.6666666666666666\n",
      "0.46153846153846156\n",
      "0.5714285714285715\n",
      "0.6666666666666666\n",
      "0.4\n",
      "0.5\n",
      "0.7142857142857143\n",
      "0.5714285714285715\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.6666666666666666\n",
      "0.4\n",
      "0.4444444444444444\n",
      "0.8\n",
      "0.8\n",
      "0.5\n",
      "0.9090909090909091\n",
      "0.5714285714285715\n",
      "0.25\n",
      "0.5714285714285715\n",
      "0.6666666666666666\n",
      "0.6666666666666665\n",
      "0.8571428571428571\n",
      "0.5714285714285715\n",
      "0.8000000000000002\n",
      "0.6666666666666665\n",
      "0.5\n",
      "0.6666666666666666\n",
      "0.7272727272727272\n",
      "0.5454545454545454\n",
      "0.6666666666666665\n",
      "0.5\n",
      "0.6666666666666666\n",
      "0.888888888888889\n",
      "0.5454545454545454\n",
      "0.6666666666666665\n",
      "0.888888888888889\n",
      "0.8333333333333333\n",
      "0.6666666666666666\n",
      "0.3636363636363636\n",
      "0.7272727272727272\n",
      "0.5714285714285715\n",
      "0.6666666666666666\n",
      "0.7692307692307692\n",
      "0.8571428571428571\n",
      "0.6666666666666665\n",
      "0.7272727272727272\n",
      "0.888888888888889\n",
      "0.7272727272727272\n",
      "0.5\n",
      "0.7272727272727272\n",
      "0.6\n",
      "0.5\n",
      "0.7499999999999999\n",
      "0.5\n",
      "0.7499999999999999\n",
      "0.5454545454545454\n",
      "0.6666666666666665\n",
      "0.7499999999999999\n",
      "0.4000000000000001\n",
      "0.6666666666666665\n",
      "0.3333333333333333\n",
      "0.5\n",
      "0.5714285714285715\n",
      "0.4\n",
      "0.25\n",
      "0.5714285714285715\n",
      "0.75\n",
      "0.4444444444444444\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "0.5454545454545454\n",
      "0.5714285714285715\n",
      "0.6666666666666665\n",
      "0.25\n",
      "0.4\n",
      "0.4444444444444445\n",
      "0.5\n",
      "0.75\n",
      "0.7692307692307692\n",
      "0.6666666666666666\n",
      "0.75\n",
      "0.4444444444444444\n",
      "0.6666666666666665\n",
      "0.8333333333333334\n",
      "0.5\n",
      "0.7692307692307693\n",
      "0.6666666666666666\n",
      "0.6666666666666665\n",
      "0.8571428571428571\n",
      "0.4000000000000001\n",
      "0.7999999999999999\n",
      "0.6666666666666665\n",
      "0.8571428571428571\n",
      "0.5714285714285715\n",
      "0.4444444444444445\n",
      "0.7272727272727272\n",
      "0.8333333333333334\n",
      "0.5\n",
      "0.888888888888889\n",
      "0.4444444444444444\n",
      "0.7142857142857143\n",
      "0.4444444444444444\n",
      "0.6666666666666666\n",
      "0.7272727272727272\n",
      "0.923076923076923\n",
      "0.4\n",
      "0.0\n",
      "0.7499999999999999\n",
      "0.4000000000000001\n",
      "0.5714285714285715\n",
      "0.6666666666666666\n",
      "0.8333333333333333\n",
      "0.5\n",
      "0.6666666666666665\n",
      "0.75\n",
      "0.5\n",
      "0.22222222222222224\n",
      "0.8333333333333333\n",
      "0.6\n",
      "0.5714285714285715\n",
      "0.8571428571428571\n",
      "0.5\n",
      "0.4444444444444445\n",
      "0.6666666666666666\n",
      "0.6\n",
      "0.75\n",
      "0.25\n",
      "0.7142857142857143\n",
      "0.7272727272727272\n",
      "0.8000000000000002\n",
      "0.28571428571428575\n",
      "0.7272727272727273\n",
      "0.5\n",
      "0.7499999999999999\n",
      "0.6666666666666665\n",
      "0.7692307692307692\n",
      "0.5714285714285715\n",
      "0.36363636363636365\n",
      "0.7499999999999999\n",
      "0.6666666666666665\n",
      "0.6\n",
      "0.4444444444444444\n",
      "0.6666666666666666\n",
      "0.5714285714285715\n",
      "0.6\n",
      "0.8\n",
      "0.2222222222222222\n",
      "0.5714285714285715\n",
      "0.5714285714285715\n",
      "0.6666666666666665\n",
      "0.5\n",
      "0.7272727272727272\n",
      "0.8000000000000002\n",
      "0.6666666666666665\n",
      "0.7499999999999999\n",
      "0.6666666666666666\n",
      "0.6666666666666666\n",
      "0.25\n",
      "0.7272727272727272\n",
      "0.6\n",
      "0.7142857142857143\n",
      "0.7692307692307693\n",
      "0.6666666666666666\n",
      "0.7692307692307693\n",
      "0.6666666666666665\n",
      "0.5\n",
      "0.8333333333333333\n",
      "0.9090909090909091\n",
      "0.5714285714285715\n",
      "0.6153846153846154\n",
      "0.75\n",
      "0.8000000000000002\n",
      "0.8000000000000002\n",
      "0.6666666666666666\n",
      "0.4444444444444445\n",
      "0.7692307692307692\n",
      "0.7272727272727273\n",
      "0.5\n",
      "0.8571428571428571\n",
      "0.4444444444444445\n",
      "0.0\n",
      "0.6\n",
      "0.4\n",
      "0.6666666666666665\n",
      "0.6666666666666666\n",
      "0.5\n",
      "0.5\n",
      "0.8333333333333334\n",
      "0.75\n",
      "0.5454545454545454\n",
      "0.6666666666666666\n",
      "0.6\n",
      "0.7692307692307693\n",
      "0.5714285714285715\n",
      "0.5454545454545454\n",
      "0.8333333333333333\n",
      "0.888888888888889\n",
      "0.22222222222222224\n",
      "0.3333333333333333\n",
      "0.7272727272727272\n",
      "0.25\n",
      "0.7272727272727273\n",
      "0.6666666666666666\n",
      "0.7692307692307692\n",
      "0.6666666666666665\n",
      "0.6666666666666665\n",
      "0.6666666666666666\n",
      "0.5454545454545454\n",
      "0.5\n",
      "0.5714285714285715\n",
      "0.7272727272727272\n",
      "0.5\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "f_score = 0\n",
    "while(f_score < 0.95):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    f_score = f1_score(y_pred=y_pred, y_true=y_val)\n",
    "    print(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(9,), learning_rate='constant',\n",
      "       learning_rate_init=0.0005, max_iter=800, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "[2 2 2 1 1 1 2 2 2 2]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "model_best = model\n",
    "y_pred_best = y_pred\n",
    "f_score_best = f_score\n",
    "print(model_best)\n",
    "print(y_pred_best)\n",
    "print(f_score_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>62</td>\n",
       "      <td>22.6562</td>\n",
       "      <td>92</td>\n",
       "      <td>3.482</td>\n",
       "      <td>0.7902</td>\n",
       "      <td>9.8648</td>\n",
       "      <td>11.2362</td>\n",
       "      <td>10.6955</td>\n",
       "      <td>703.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>23.0100</td>\n",
       "      <td>82</td>\n",
       "      <td>5.663</td>\n",
       "      <td>1.1454</td>\n",
       "      <td>35.5900</td>\n",
       "      <td>26.7200</td>\n",
       "      <td>4.5800</td>\n",
       "      <td>174.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>25.7000</td>\n",
       "      <td>94</td>\n",
       "      <td>8.079</td>\n",
       "      <td>1.8733</td>\n",
       "      <td>65.9260</td>\n",
       "      <td>3.7412</td>\n",
       "      <td>4.4968</td>\n",
       "      <td>206.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>44</td>\n",
       "      <td>27.8876</td>\n",
       "      <td>99</td>\n",
       "      <td>9.208</td>\n",
       "      <td>2.2486</td>\n",
       "      <td>12.6757</td>\n",
       "      <td>5.4782</td>\n",
       "      <td>23.0331</td>\n",
       "      <td>407.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>75</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>83</td>\n",
       "      <td>4.952</td>\n",
       "      <td>1.0138</td>\n",
       "      <td>17.1270</td>\n",
       "      <td>11.5790</td>\n",
       "      <td>7.0913</td>\n",
       "      <td>318.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84</td>\n",
       "      <td>53</td>\n",
       "      <td>36.7902</td>\n",
       "      <td>101</td>\n",
       "      <td>10.175</td>\n",
       "      <td>2.5349</td>\n",
       "      <td>27.1841</td>\n",
       "      <td>20.0300</td>\n",
       "      <td>10.2631</td>\n",
       "      <td>695.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89</td>\n",
       "      <td>49</td>\n",
       "      <td>20.9566</td>\n",
       "      <td>94</td>\n",
       "      <td>12.305</td>\n",
       "      <td>2.8531</td>\n",
       "      <td>11.2406</td>\n",
       "      <td>8.4122</td>\n",
       "      <td>23.1177</td>\n",
       "      <td>573.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>21.0828</td>\n",
       "      <td>102</td>\n",
       "      <td>6.200</td>\n",
       "      <td>1.5599</td>\n",
       "      <td>9.6994</td>\n",
       "      <td>8.5747</td>\n",
       "      <td>13.7424</td>\n",
       "      <td>448.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>31.2500</td>\n",
       "      <td>199</td>\n",
       "      <td>12.162</td>\n",
       "      <td>5.9699</td>\n",
       "      <td>18.1314</td>\n",
       "      <td>4.1041</td>\n",
       "      <td>53.6308</td>\n",
       "      <td>1698.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>31.2500</td>\n",
       "      <td>103</td>\n",
       "      <td>4.328</td>\n",
       "      <td>1.0996</td>\n",
       "      <td>25.7816</td>\n",
       "      <td>12.7190</td>\n",
       "      <td>38.6531</td>\n",
       "      <td>775.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>112</td>\n",
       "      <td>86</td>\n",
       "      <td>27.1800</td>\n",
       "      <td>138</td>\n",
       "      <td>19.910</td>\n",
       "      <td>6.7774</td>\n",
       "      <td>90.2800</td>\n",
       "      <td>14.1100</td>\n",
       "      <td>4.3500</td>\n",
       "      <td>90.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>86</td>\n",
       "      <td>26.6667</td>\n",
       "      <td>201</td>\n",
       "      <td>41.611</td>\n",
       "      <td>20.6307</td>\n",
       "      <td>47.6470</td>\n",
       "      <td>5.3571</td>\n",
       "      <td>24.3701</td>\n",
       "      <td>1698.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>72</td>\n",
       "      <td>23.6200</td>\n",
       "      <td>105</td>\n",
       "      <td>4.420</td>\n",
       "      <td>1.1448</td>\n",
       "      <td>21.7800</td>\n",
       "      <td>17.8600</td>\n",
       "      <td>4.8200</td>\n",
       "      <td>195.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>32.4619</td>\n",
       "      <td>134</td>\n",
       "      <td>24.887</td>\n",
       "      <td>8.2260</td>\n",
       "      <td>42.3914</td>\n",
       "      <td>10.7939</td>\n",
       "      <td>5.7680</td>\n",
       "      <td>656.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>76</td>\n",
       "      <td>64</td>\n",
       "      <td>34.5297</td>\n",
       "      <td>95</td>\n",
       "      <td>4.427</td>\n",
       "      <td>1.0374</td>\n",
       "      <td>21.2117</td>\n",
       "      <td>5.4626</td>\n",
       "      <td>6.7019</td>\n",
       "      <td>252.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>71</td>\n",
       "      <td>58</td>\n",
       "      <td>29.1545</td>\n",
       "      <td>139</td>\n",
       "      <td>16.582</td>\n",
       "      <td>5.6854</td>\n",
       "      <td>22.8884</td>\n",
       "      <td>10.2627</td>\n",
       "      <td>13.9740</td>\n",
       "      <td>923.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>20.8300</td>\n",
       "      <td>88</td>\n",
       "      <td>3.420</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>12.8700</td>\n",
       "      <td>18.5500</td>\n",
       "      <td>13.5600</td>\n",
       "      <td>301.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>34.8381</td>\n",
       "      <td>95</td>\n",
       "      <td>12.548</td>\n",
       "      <td>2.9404</td>\n",
       "      <td>33.1612</td>\n",
       "      <td>2.3650</td>\n",
       "      <td>9.9542</td>\n",
       "      <td>655.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>60</td>\n",
       "      <td>73</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>97</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.8015</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>10.3587</td>\n",
       "      <td>6.2844</td>\n",
       "      <td>136.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>98</td>\n",
       "      <td>89</td>\n",
       "      <td>22.7000</td>\n",
       "      <td>77</td>\n",
       "      <td>4.690</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>6.9640</td>\n",
       "      <td>5.5899</td>\n",
       "      <td>12.9361</td>\n",
       "      <td>1256.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>22.8928</td>\n",
       "      <td>103</td>\n",
       "      <td>2.740</td>\n",
       "      <td>0.6961</td>\n",
       "      <td>8.0163</td>\n",
       "      <td>9.3498</td>\n",
       "      <td>11.5549</td>\n",
       "      <td>359.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>59</td>\n",
       "      <td>45</td>\n",
       "      <td>20.8300</td>\n",
       "      <td>74</td>\n",
       "      <td>4.560</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>8.2374</td>\n",
       "      <td>28.0323</td>\n",
       "      <td>382.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>32.0390</td>\n",
       "      <td>85</td>\n",
       "      <td>18.077</td>\n",
       "      <td>3.7901</td>\n",
       "      <td>30.7729</td>\n",
       "      <td>7.7803</td>\n",
       "      <td>13.6839</td>\n",
       "      <td>444.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>31.2386</td>\n",
       "      <td>82</td>\n",
       "      <td>4.181</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>16.2247</td>\n",
       "      <td>4.2671</td>\n",
       "      <td>3.2918</td>\n",
       "      <td>634.602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Age      BMI  Glucose  Insulin     HOMA   Leptin  Adiponectin  \\\n",
       "0   100   62  22.6562       92    3.482   0.7902   9.8648      11.2362   \n",
       "1    78   29  23.0100       82    5.663   1.1454  35.5900      26.7200   \n",
       "2    77   75  25.7000       94    8.079   1.8733  65.9260       3.7412   \n",
       "3   113   44  27.8876       99    9.208   2.2486  12.6757       5.4782   \n",
       "4    86   75  23.0000       83    4.952   1.0138  17.1270      11.5790   \n",
       "5    84   53  36.7902      101   10.175   2.5349  27.1841      20.0300   \n",
       "6    89   49  20.9566       94   12.305   2.8531  11.2406       8.4122   \n",
       "7    56   68  21.0828      102    6.200   1.5599   9.6994       8.5747   \n",
       "8    31   48  31.2500      199   12.162   5.9699  18.1314       4.1041   \n",
       "9    48   43  31.2500      103    4.328   1.0996  25.7816      12.7190   \n",
       "10  112   86  27.1800      138   19.910   6.7774  90.2800      14.1100   \n",
       "11   36   86  26.6667      201   41.611  20.6307  47.6470       5.3571   \n",
       "12   21   72  23.6200      105    4.420   1.1448  21.7800      17.8600   \n",
       "13   11   49  32.4619      134   24.887   8.2260  42.3914      10.7939   \n",
       "14   76   64  34.5297       95    4.427   1.0374  21.2117       5.4626   \n",
       "15   71   58  29.1545      139   16.582   5.6854  22.8884      10.2627   \n",
       "16   53   46  20.8300       88    3.420   0.7424  12.8700      18.5500   \n",
       "17   63   57  34.8381       95   12.548   2.9404  33.1612       2.3650   \n",
       "18   60   73  22.0000       97    3.350   0.8015   4.4700      10.3587   \n",
       "19   98   89  22.7000       77    4.690   0.8908   6.9640       5.5899   \n",
       "20   14   51  22.8928      103    2.740   0.6961   8.0163       9.3498   \n",
       "21   59   45  20.8300       74    4.560   0.8324   7.7529       8.2374   \n",
       "22   58   61  32.0390       85   18.077   3.7901  30.7729       7.7803   \n",
       "23   85   66  31.2386       82    4.181   0.8457  16.2247       4.2671   \n",
       "\n",
       "    Resistin     MCP.1  \n",
       "0    10.6955   703.973  \n",
       "1     4.5800   174.800  \n",
       "2     4.4968   206.802  \n",
       "3    23.0331   407.206  \n",
       "4     7.0913   318.302  \n",
       "5    10.2631   695.754  \n",
       "6    23.1177   573.630  \n",
       "7    13.7424   448.799  \n",
       "8    53.6308  1698.440  \n",
       "9    38.6531   775.322  \n",
       "10    4.3500    90.090  \n",
       "11   24.3701  1698.440  \n",
       "12    4.8200   195.940  \n",
       "13    5.7680   656.393  \n",
       "14    6.7019   252.449  \n",
       "15   13.9740   923.886  \n",
       "16   13.5600   301.210  \n",
       "17    9.9542   655.834  \n",
       "18    6.2844   136.855  \n",
       "19   12.9361  1256.083  \n",
       "20   11.5549   359.232  \n",
       "21   28.0323   382.955  \n",
       "22   13.6839   444.395  \n",
       "23    3.2918   634.602  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.iloc[:,1:]\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['id'] = df_test.id\n",
    "submission['Classification'] = y_pred\n",
    "submission.to_csv('my_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
